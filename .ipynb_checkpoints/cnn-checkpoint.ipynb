{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "import the modules and get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              pixels emotion\n",
      "0  25 23 25 29 29 32 28 20 34 63 77 85 110 141 15...   anger\n",
      "1  84 84 53 23 17 16 15 11 19 11 11 7 0 15 62 140...   happy\n",
      "2  44 37 24 34 43 67 89 111 115 124 137 159 173 1...   happy\n",
      "3  116 116 113 74 27 19 15 15 18 22 43 77 106 121...   happy\n",
      "4  14 6 2 4 11 21 29 58 84 114 144 157 165 177 18...   happy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import cv2\n",
    "import data\n",
    "import model\n",
    "from PIL import Image\n",
    "import dlib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data.get_files_CNN()\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the dataset to data we can actually use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[25.]\n",
      "  [23.]\n",
      "  [25.]\n",
      "  ...\n",
      "  [24.]\n",
      "  [29.]\n",
      "  [39.]]\n",
      "\n",
      " [[24.]\n",
      "  [23.]\n",
      "  [25.]\n",
      "  ...\n",
      "  [26.]\n",
      "  [23.]\n",
      "  [25.]]\n",
      "\n",
      " [[25.]\n",
      "  [23.]\n",
      "  [25.]\n",
      "  ...\n",
      "  [29.]\n",
      "  [22.]\n",
      "  [22.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[20.]\n",
      "  [11.]\n",
      "  [17.]\n",
      "  ...\n",
      "  [58.]\n",
      "  [ 1.]\n",
      "  [14.]]\n",
      "\n",
      " [[24.]\n",
      "  [10.]\n",
      "  [18.]\n",
      "  ...\n",
      "  [52.]\n",
      "  [19.]\n",
      "  [ 3.]]\n",
      "\n",
      " [[25.]\n",
      "  [ 9.]\n",
      "  [18.]\n",
      "  ...\n",
      "  [33.]\n",
      "  [15.]\n",
      "  [ 0.]]]\n"
     ]
    }
   ],
   "source": [
    "image_size = (48, 48)\n",
    "pixels = df['pixels'].tolist()  # Converting the relevant column element into a list for each row\n",
    "width, height = 48, 48\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')]  # Splitting the string by space character as a list\n",
    "    face = np.asarray(face).reshape(width, height)  # converting the list to numpy array in size of 48*48\n",
    "    face = cv2.resize(face.astype('uint8'), image_size)  # resize the image to have 48 cols (width) and 48 rows (height)\n",
    "    faces.append(face.astype('float32'))  # makes the list of each images of 48*48 and their pixels in numpyarray form\n",
    "\n",
    "faces = np.asarray(faces)  # converting the list into numpy array\n",
    "faces = np.expand_dims(faces, -1)  # Expand the shape of an array -1=last dimension => means color space\n",
    "emotions = pd.get_dummies(df['emotion']).to_numpy()  # doing the one hot encoding type on emotions\n",
    "\n",
    "print(faces[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how the faces look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 48, 48, 1)\n",
      "3\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(faces.shape)\n",
    "print(faces[0].ndim)\n",
    "print(type(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the emotions after preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0]\n",
      "(480, 4)\n",
      "2\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(emotions[0]) #Emotion after preprocessing\n",
    "print(emotions.shape)\n",
    "print(emotions.ndim)\n",
    "print(type(emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time to scale the pixels and check if the min and max are -1.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.8039216 ]\n",
      "  [-0.81960785]\n",
      "  [-0.8039216 ]\n",
      "  ...\n",
      "  [-0.8117647 ]\n",
      "  [-0.77254903]\n",
      "  [-0.69411767]]\n",
      "\n",
      " [[-0.8117647 ]\n",
      "  [-0.81960785]\n",
      "  [-0.8039216 ]\n",
      "  ...\n",
      "  [-0.79607844]\n",
      "  [-0.81960785]\n",
      "  [-0.8039216 ]]\n",
      "\n",
      " [[-0.8039216 ]\n",
      "  [-0.81960785]\n",
      "  [-0.8039216 ]\n",
      "  ...\n",
      "  [-0.77254903]\n",
      "  [-0.827451  ]\n",
      "  [-0.827451  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.84313726]\n",
      "  [-0.9137255 ]\n",
      "  [-0.8666667 ]\n",
      "  ...\n",
      "  [-0.54509807]\n",
      "  [-0.99215686]\n",
      "  [-0.8901961 ]]\n",
      "\n",
      " [[-0.8117647 ]\n",
      "  [-0.92156863]\n",
      "  [-0.85882354]\n",
      "  ...\n",
      "  [-0.5921569 ]\n",
      "  [-0.8509804 ]\n",
      "  [-0.9764706 ]]\n",
      "\n",
      " [[-0.8039216 ]\n",
      "  [-0.92941177]\n",
      "  [-0.85882354]\n",
      "  ...\n",
      "  [-0.7411765 ]\n",
      "  [-0.88235295]\n",
      "  [-1.        ]]]\n",
      "-1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "x = faces.astype('float32')\n",
    "x = x / 255.0 #Dividing the pixels by 255 for normalization  => range(0,1)\n",
    "\n",
    "# Scaling the pixels value in range(-1,1)\n",
    "x = x - 0.5\n",
    "x = x * 2.0\n",
    "print(x[0])\n",
    "print(x.min(),x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pixels (384, 48, 48, 1)\n",
      "Training labels (384, 4)\n",
      "Validation Pixels (96, 48, 48, 1)\n",
      "Validation labels (96, 4)\n"
     ]
    }
   ],
   "source": [
    "num_samples, num_classes = emotions.shape\n",
    "\n",
    "num_samples = len(x)\n",
    "num_train_samples = int((1 - 0.2)*num_samples)\n",
    "\n",
    "# Traning data\n",
    "train_x = x[:num_train_samples]\n",
    "train_y = emotions[:num_train_samples]\n",
    "\n",
    "# Validation data\n",
    "val_x = x[num_train_samples:]\n",
    "val_y = emotions[num_train_samples:]\n",
    "\n",
    "train_data = (train_x, train_y)\n",
    "val_data = (val_x, val_y)\n",
    "\n",
    "print('Training Pixels',train_x.shape)  # ==> 4 dims -  no of images , width , height , color\n",
    "print('Training labels',train_y.shape)\n",
    "\n",
    "print('Validation Pixels',val_x.shape)\n",
    "print('Validation labels',val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import keras for the model training and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the model with it's layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 24, 24, 48)        1248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 24, 24, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 10, 10, 48)        57648     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               614912    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 3591      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 677,399\n",
      "Trainable params: 677,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(48, 48, 1)\n",
    "num_classes = 4\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(48, (5, 5), strides = (2,2), padding='same', input_shape=input_shape))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(48, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.1664 - accuracy: 0.9583 - val_loss: 0.1348 - val_accuracy: 0.9479\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: 0.1394 - val_accuracy: 0.9479\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0591 - accuracy: 0.9818 - val_loss: 0.1300 - val_accuracy: 0.9583\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0471 - accuracy: 0.9870 - val_loss: 0.1442 - val_accuracy: 0.9375\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0414 - accuracy: 0.9948 - val_loss: 0.1756 - val_accuracy: 0.9375\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.1264 - val_accuracy: 0.9479\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.0802 - val_accuracy: 0.9688\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.1790 - val_accuracy: 0.9167\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0247 - accuracy: 0.9948 - val_loss: 0.1204 - val_accuracy: 0.9375\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0185 - accuracy: 0.9974 - val_loss: 0.1462 - val_accuracy: 0.9271\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9688\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 0.0626 - val_accuracy: 0.9583\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9583\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9375\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "opt = RMSprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist_model_1 = model_1.fit(train_x, train_y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(val_x, val_y),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'-x', label=\"Train Loss\", color='red')\n",
    "    ax.plot(history.history[\"val_loss\"],'-x', label=\"Validation Loss\", color='blue')\n",
    "    ax.legend()\n",
    "    ax.set_title('cross_entropy loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"accuracy\"],'-x', label=\"Train Accuracy\", color='red')\n",
    "    ax.plot(history.history[\"val_accuracy\"],'-x', label=\"Validation Accuracy\", color='blue')\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    ax.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(hist_model_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
